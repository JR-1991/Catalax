---
title: universalode
sidebarTitle: universalode
---

# `catalax.neural.universalode`

## Classes

### `UniversalODE` <sup><a href="https://github.com/JR-1991/Catalax/blob/master/catalax/neural/universalode.py#L20" target="_blank"><Icon icon="github" style="width: 14px; height: 14px;" /></a></sup>

**Methods:**

#### `corrective_term` <sup><a href="https://github.com/JR-1991/Catalax/blob/master/catalax/neural/universalode.py#L128" target="_blank"><Icon icon="github" style="width: 14px; height: 14px;" /></a></sup>

```python
corrective_term(self, dataset: Dataset) -> tuple[jax.Array, jax.Array]
```

Get the corrective term of the model at the given states.

The corrective term is the neural network contribution to the rates.


#### `plot_corrections_over_time` <sup><a href="https://github.com/JR-1991/Catalax/blob/master/catalax/neural/universalode.py#L141" target="_blank"><Icon icon="github" style="width: 14px; height: 14px;" /></a></sup>

```python
plot_corrections_over_time(self, dataset: Dataset, show: bool = True, path: Optional[str] = None, n_steps: int = 100, figsize: tuple[float, float] = (10, 3.5)) -> Optional[Figure]
```

#### `plot_corrections_over_input` <sup><a href="https://github.com/JR-1991/Catalax/blob/master/catalax/neural/universalode.py#L218" target="_blank"><Icon icon="github" style="width: 14px; height: 14px;" /></a></sup>

```python
plot_corrections_over_input(self, dataset: Dataset, show: bool = True, path: Optional[str] = None, figsize: tuple[float, float] = (10, 3.5)) -> Optional[Figure]
```

#### `gate_activation` <sup><a href="https://github.com/JR-1991/Catalax/blob/master/catalax/neural/universalode.py#L273" target="_blank"><Icon icon="github" style="width: 14px; height: 14px;" /></a></sup>

```python
gate_activation(self, y: jax.Array) -> jax.Array
```

Get the gate of the model at the given states.

The gate is a smooth function that determines if the neural network
contribution is active or not. The gate is triggered by state concentrations
that flow into a sigmoid function. The row weights of the gate matrix determine
the sensitivity of the gate to each state. weights can cancel out each other and
thus cross-talk between states can be controlled.

**Args:**
- `y`: jax.Array of shape (n_state,) or (n_time, n_state)

**Returns:**
- Gate


#### `get_alpha_residual` <sup><a href="https://github.com/JR-1991/Catalax/blob/master/catalax/neural/universalode.py#L299" target="_blank"><Icon icon="github" style="width: 14px; height: 14px;" /></a></sup>

```python
get_alpha_residual(self) -> jax.Array
```

Get the alpha residual of the model.

The alpha residual is a scalar that scales the neural network contribution.
This way and in combination with L1 regularization can introduce sparsity
in the neural network contribution. This is particularly useful for symbolic
regression to recover corrective terms.

**Returns:**
- Alpha residual


#### `get_rates` <sup><a href="https://github.com/JR-1991/Catalax/blob/master/catalax/neural/universalode.py#L312" target="_blank"><Icon icon="github" style="width: 14px; height: 14px;" /></a></sup>

```python
get_rates(self, t: jax.Array, y: jax.Array) -> jax.Array
```

Get the rates of the model.

This basically evaluates the MLP at the given time points and states, which
is useful for quiver plots and MCMC surrogates.

**Args:**
- `t`: Time points
- `y`: States

**Returns:**
- Rates

